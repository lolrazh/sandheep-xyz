 The reason I find myself writing this post is because I think most AI-powered CAD applications suck.

If you weren’t offended by the first statement and did make it to the second line, let me bring up a story known to all of us and try to map it back to my reasoning behind making such a statement.

When electricity was first invented, it would’ve been absurd to just slap it on a gas-powered lamp and call it an electric lamp. Think about how stupid an electricity-powered gas-powered lamp sounds to us today. Although funnily enough at first, gas lamps with electronic ignition systems were indeed developed. They would automatically relight gas lamps upon blowout, using electricity for ignition while gas remained as the primary fuel source. But the true potential of electricity was only realized when people stopped treating it as just an upgrade and saw it as a complete replacement. Only then did they abandon the flame entirely—and in its place, invent the glowing filament.

AI, like electricity, requires the same rethinking. It’s not about retrofitting AI onto old processes—it’s about using AI to *reimagine* the process entirely. Most AI-powered apps fail because they don’t respect this principle. They’re like gas lamps with an electric spark: clunky, inefficient, and ultimately unnecessary. The AI-powered software isn’t solving any problems, other than adding an extra step and looking incredibly cool. Some argue that AI-powered tools at least make things more accessible, flattening the skill curve. But is accessibility alone enough? Are we actually making tools easier, or just shifting the complexity elsewhere? Because replacing buttons with a text box doesn’t automatically make things easier. Thinking through words is hard. Writing is harder. Most users don’t even know what they want half the time. The result? Confusion, frustration, and a tool that feels more like a chore than a solution. So the electric lamp question for us isn’t *how* we apply AI to CAD—it’s *why* we’re still designing this way in the first place. To understand that, we need to look at why CAD even exists.

Before CAD, how did people create and share their ideas? If you wanted to build something three-dimensional, you’d sculpt it. But sharing those ideas with others required the most advanced technology of that time—paper. Orthographic drawings became the standard not because they were intuitive, but because they were the best way to communicate ideas. The introduction of CAD only digitized this process. And over the years, we slapped another dimension onto it. Of course, this is an oversimplification—but stepping back gives us perspective on where CAD came from and where it needs to go.

The spirit of CAD lies in eliminating the friction (pun intended) it takes in producing something. What would a *truly* AI-native CAD software look? Would it even have a screen? A mouse? Would it be something we *describe*, something we *sculpt*, or something else entirely?

Right now, we don’t have a clear answer—and that’s okay. It’s at least the question we need to be asking. It’s not enough to slap on text prompts or sprinkle in some generative AI features and call it revolutionary. AI-native software would be something fundamentally different, something that doesn’t just make our current workflows slightly easier but redefines *how* we work altogether. How do we build something that makes complex tasks feel effortless? How do we build something that creates entirely new ways of working that were previously unimaginable?

If the goal of design is to communicate ideas, why are there so many steps between what’s in your head and what’s on the screen? Why are we still constrained by tools that demand precision, orthographic projections, and countless clicks, when what we really want is to *shape* an idea as naturally as we think about it?

Maybe the time has come for us to invent the glowing filament. And maybe, just maybe, we shouldn’t wait for someone else to do it.